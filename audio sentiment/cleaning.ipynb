{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder = \"../dataset/\"\n",
    "# emotion_cat = []\n",
    "# mfcc = []\n",
    "# zcr = []\n",
    "# rmse = []\n",
    "# # centroid_list = []\n",
    "# # bandwidth_list = []\n",
    "# # contrast_list = []\n",
    "# # chroma_list = []\n",
    "# # rhythm = []\n",
    "\n",
    "# all_features = []\n",
    "# total_feature_len = []\n",
    "\n",
    "# emotion_dict = {\n",
    "#     \"01\":\"neutral\",\n",
    "#     \"02\":\"calm\",\n",
    "#     \"03\":\"happy\",\n",
    "#     \"04\":\"sad\",\n",
    "#     \"05\":\"angry\",\n",
    "#     \"06\":\"fearful\",\n",
    "#     \"07\":\"disgust\",\n",
    "#     \"08\":\"surprised\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt = 0\n",
    "# for subfolder in os.listdir(folder):\n",
    "#     for file in os.listdir(f\"{folder}/{subfolder}\"):\n",
    "\n",
    "#         emotion_cat.append(int((f\"{folder}/{subfolder}/{file}\".split('-')[2])[1]))\n",
    "#         audio,s_r = librosa.load(f\"{folder}/{subfolder}/{file}\")\n",
    "\n",
    "#         mel_freq = np.mean(librosa.feature.mfcc(y = audio, sr = s_r, n_mfcc=50).T, axis = 0).reshape(-1)\n",
    "\n",
    "#         zero_cross = np.pad((librosa.feature.zero_crossing_rate(y = audio).reshape(-1)),\n",
    "#                                (0,(228-len(librosa.feature.zero_crossing_rate(y = audio).reshape(-1)))),\n",
    "#                                'constant',\n",
    "#                                constant_values=(0,0))\n",
    "\n",
    "#         rms = np.pad((librosa.feature.rms(y = audio).reshape(-1)),\n",
    "#                                (0,(228-len(librosa.feature.rms(y = audio).reshape(-1)))),\n",
    "#                                'constant',\n",
    "#                                constant_values=(0,0))\n",
    "        \n",
    "        \n",
    "#         # spec_centroid = np.pad((librosa.feature.spectral_centroid(y = audio, sr = s_r).reshape(-1)),\n",
    "#         #                        (0,(228-len(librosa.feature.spectral_centroid(y = audio, sr = s_r).reshape(-1)))),\n",
    "#         #                        'constant',\n",
    "#         #                        constant_values=(0,0))\n",
    "        \n",
    "#         # spec_bandwidth = np.pad((librosa.feature.spectral_bandwidth(y = audio, sr = s_r).reshape(-1)),\n",
    "#         #                        (0,(228-len(librosa.feature.spectral_bandwidth(y = audio, sr = s_r).reshape(-1)))),\n",
    "#         #                        'constant',\n",
    "#         #                        constant_values=(0,0))\n",
    "        \n",
    "#         # spec_contrast = np.pad((librosa.feature.spectral_contrast(y = audio, sr = s_r).reshape(-1)),\n",
    "#         #                        (0,(1596-len(librosa.feature.spectral_contrast(y = audio, sr = s_r).reshape(-1)))),\n",
    "#         #                        'constant',\n",
    "#         #                        constant_values=(0,0))\n",
    "        \n",
    "#         # chroma = np.pad((librosa.feature.chroma_stft(y=audio, sr=s_r).reshape(-1)),\n",
    "#         #                        (0,(2736-len(librosa.feature.chroma_stft(y = audio, sr = s_r).reshape(-1)))),\n",
    "#         #                        'constant',\n",
    "#         #                        constant_values=(0,0))\n",
    "        \n",
    "#         # tempogram = np.pad((librosa.feature.tempogram(y=audio, sr=s_r).reshape(-1)),\n",
    "#         #                        (0,(87552-len(librosa.feature.tempogram(y = audio, sr = s_r).reshape(-1)))),\n",
    "#         #                        'constant',\n",
    "#         #                        constant_values=(0,0))\n",
    "        \n",
    "#         mfcc.append(mel_freq)\n",
    "#         zcr.append(zero_cross)\n",
    "#         rmse.append(rms)\n",
    "#         # centroid_list.append(spec_centroid)\n",
    "#         # bandwidth_list.append(spec_bandwidth)\n",
    "#         # contrast_list.append(spec_contrast)\n",
    "#         # chroma_list.append(chroma)\n",
    "#         # rhythm.append(tempogram)\n",
    "#         all_features.append(np.hstack((mel_freq,zero_cross,rms)))\n",
    "#         cnt+=1\n",
    "#         print(cnt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\"x\":np.array(all_features), \"y\": np.array(emotion_cat)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"data2.pkl\", \"wb\") as pick:\n",
    "#     pickle.dump(data,pick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame({\"emotion\":np.array(emotion_cat).flatten(),\n",
    "#                      \"melfreq\":np.array(mfcc),\n",
    "#                      \"spec_centroid\":np.array(centroid_list),\n",
    "#                      \"spec_bandwidth\":np.array(bandwidth_list),\n",
    "#                      \"spec_contrast\":np.array(contrast_list),\n",
    "#                      \"chroma\":np.array(chroma_list),\n",
    "#                      \"rhythm\":np.array(rhythm),\n",
    "#                      \"all\":np.array(all_features)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.to_csv('../dataset/audio_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(all_features).shape, np.array(emotion_cat).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data2.pkl', \"rb\") as data:\n",
    "    info = pickle.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "x = np.array(info['x'])\n",
    "lb = LabelEncoder()\n",
    "y = to_categorical(lb.fit_transform(np.array(info['y'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain, xtest, ytrain,  ytest = train_test_split(x, y,test_size=0.2, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Dense, Dropout, LSTM,Conv1D, BatchNormalization, MaxPool1D, MaxPooling1D,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(512, kernel_size=5, strides=1,\n",
    "                        padding=\"same\", activation=\"relu\",\n",
    "                        input_shape=(xtrain.shape[1], 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=5, strides=2, padding=\"same\"))\n",
    "\n",
    "model.add(Conv1D(512, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=5, strides = 2, padding = 'same'))\n",
    "\n",
    "model.add(Conv1D(128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=3, strides = 2, padding = 'same'))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model.add(Dense(8, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_6 (Conv1D)           (None, 506, 512)          3072      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 506, 512)         2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 253, 512)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 253, 512)          786944    \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 253, 512)         2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_7 (MaxPooling  (None, 127, 512)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 127, 256)          393472    \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 127, 256)         1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 64, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 64, 256)           196864    \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 64, 256)          1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_9 (MaxPooling  (None, 32, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 32, 128)           98432     \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 32, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 16, 128)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 16, 128)           49280     \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 16, 128)          512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling1d_11 (MaxPoolin  (None, 8, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 128)              512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,833,096\n",
      "Trainable params: 1,828,744\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('ser.h5',\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True,\n",
    "                             mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ser.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('./ser.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 2.1547 - accuracy: 0.2422\n",
      "Epoch 1: val_accuracy improved from -inf to 0.12500, saving model to ser.h5\n",
      "72/72 [==============================] - 5s 35ms/step - loss: 2.1547 - accuracy: 0.2422 - val_loss: 32.2663 - val_accuracy: 0.1250\n",
      "Epoch 2/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.8110 - accuracy: 0.3299\n",
      "Epoch 2: val_accuracy improved from 0.12500 to 0.13542, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 30ms/step - loss: 1.8110 - accuracy: 0.3299 - val_loss: 44.4755 - val_accuracy: 0.1354\n",
      "Epoch 3/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.6605 - accuracy: 0.3924\n",
      "Epoch 3: val_accuracy did not improve from 0.13542\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 1.6605 - accuracy: 0.3924 - val_loss: 24.4118 - val_accuracy: 0.1111\n",
      "Epoch 4/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.6432 - accuracy: 0.3536\n",
      "Epoch 4: val_accuracy did not improve from 0.13542\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 1.6305 - accuracy: 0.3620 - val_loss: 14.6066 - val_accuracy: 0.1354\n",
      "Epoch 5/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.5858 - accuracy: 0.3961\n",
      "Epoch 5: val_accuracy improved from 0.13542 to 0.13889, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 1.5933 - accuracy: 0.3950 - val_loss: 9.7143 - val_accuracy: 0.1389\n",
      "Epoch 6/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.5056 - accuracy: 0.4179\n",
      "Epoch 6: val_accuracy improved from 0.13889 to 0.20139, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 1.5121 - accuracy: 0.4167 - val_loss: 5.6267 - val_accuracy: 0.2014\n",
      "Epoch 7/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.4317 - accuracy: 0.4586\n",
      "Epoch 7: val_accuracy improved from 0.20139 to 0.24653, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 1.4372 - accuracy: 0.4557 - val_loss: 3.8919 - val_accuracy: 0.2465\n",
      "Epoch 8/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.3868 - accuracy: 0.4714\n",
      "Epoch 8: val_accuracy did not improve from 0.24653\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 1.3752 - accuracy: 0.4766 - val_loss: 3.1687 - val_accuracy: 0.1944\n",
      "Epoch 9/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.3432 - accuracy: 0.4947\n",
      "Epoch 9: val_accuracy did not improve from 0.24653\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 1.3437 - accuracy: 0.4939 - val_loss: 3.4527 - val_accuracy: 0.1458\n",
      "Epoch 10/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.2823 - accuracy: 0.5054\n",
      "Epoch 10: val_accuracy improved from 0.24653 to 0.26736, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 1.2886 - accuracy: 0.5043 - val_loss: 2.7330 - val_accuracy: 0.2674\n",
      "Epoch 11/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 1.2726 - accuracy: 0.5295\n",
      "Epoch 11: val_accuracy did not improve from 0.26736\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 1.2726 - accuracy: 0.5295 - val_loss: 2.7389 - val_accuracy: 0.2361\n",
      "Epoch 12/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.1953 - accuracy: 0.5546\n",
      "Epoch 12: val_accuracy did not improve from 0.26736\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 1.1987 - accuracy: 0.5521 - val_loss: 4.4272 - val_accuracy: 0.1111\n",
      "Epoch 13/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 1.1354 - accuracy: 0.5792\n",
      "Epoch 13: val_accuracy did not improve from 0.26736\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 1.1318 - accuracy: 0.5799 - val_loss: 2.5375 - val_accuracy: 0.2674\n",
      "Epoch 14/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.1328 - accuracy: 0.5670\n",
      "Epoch 14: val_accuracy did not improve from 0.26736\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 1.1252 - accuracy: 0.5720 - val_loss: 2.9682 - val_accuracy: 0.1667\n",
      "Epoch 15/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.0785 - accuracy: 0.5902\n",
      "Epoch 15: val_accuracy did not improve from 0.26736\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 1.0820 - accuracy: 0.5877 - val_loss: 3.8805 - val_accuracy: 0.1875\n",
      "Epoch 16/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 1.0068 - accuracy: 0.6250\n",
      "Epoch 16: val_accuracy did not improve from 0.26736\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 1.0169 - accuracy: 0.6259 - val_loss: 4.8166 - val_accuracy: 0.1736\n",
      "Epoch 17/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.9750 - accuracy: 0.6455\n",
      "Epoch 17: val_accuracy did not improve from 0.26736\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.9708 - accuracy: 0.6458 - val_loss: 8.2594 - val_accuracy: 0.1771\n",
      "Epoch 18/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.9407 - accuracy: 0.6510\n",
      "Epoch 18: val_accuracy improved from 0.26736 to 0.39583, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.9407 - accuracy: 0.6510 - val_loss: 2.1241 - val_accuracy: 0.3958\n",
      "Epoch 19/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8736 - accuracy: 0.6727\n",
      "Epoch 19: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.8736 - accuracy: 0.6727 - val_loss: 5.8665 - val_accuracy: 0.1632\n",
      "Epoch 20/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.8622 - accuracy: 0.6585\n",
      "Epoch 20: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.8580 - accuracy: 0.6606 - val_loss: 3.0895 - val_accuracy: 0.2639\n",
      "Epoch 21/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.8519 - accuracy: 0.6788\n",
      "Epoch 21: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.8519 - accuracy: 0.6788 - val_loss: 4.1251 - val_accuracy: 0.2639\n",
      "Epoch 22/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.8088 - accuracy: 0.7148\n",
      "Epoch 22: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.8067 - accuracy: 0.7144 - val_loss: 8.8688 - val_accuracy: 0.1493\n",
      "Epoch 23/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.7365 - accuracy: 0.7295\n",
      "Epoch 23: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.7329 - accuracy: 0.7318 - val_loss: 5.0300 - val_accuracy: 0.2604\n",
      "Epoch 24/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.6961 - accuracy: 0.7482\n",
      "Epoch 24: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.6945 - accuracy: 0.7483 - val_loss: 5.8410 - val_accuracy: 0.1632\n",
      "Epoch 25/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.6791 - accuracy: 0.7455\n",
      "Epoch 25: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.6802 - accuracy: 0.7457 - val_loss: 3.8736 - val_accuracy: 0.2188\n",
      "Epoch 26/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.5798 - accuracy: 0.7884\n",
      "Epoch 26: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.5800 - accuracy: 0.7873 - val_loss: 3.4055 - val_accuracy: 0.2986\n",
      "Epoch 27/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.7812\n",
      "Epoch 27: val_accuracy did not improve from 0.39583\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.6019 - accuracy: 0.7812 - val_loss: 3.6988 - val_accuracy: 0.3021\n",
      "Epoch 28/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.5649 - accuracy: 0.8046\n",
      "Epoch 28: val_accuracy improved from 0.39583 to 0.40972, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.5641 - accuracy: 0.8056 - val_loss: 2.7389 - val_accuracy: 0.4097\n",
      "Epoch 29/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.5219 - accuracy: 0.8143\n",
      "Epoch 29: val_accuracy did not improve from 0.40972\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.5264 - accuracy: 0.8142 - val_loss: 5.9666 - val_accuracy: 0.2535\n",
      "Epoch 30/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.5297 - accuracy: 0.7920\n",
      "Epoch 30: val_accuracy did not improve from 0.40972\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.5358 - accuracy: 0.7908 - val_loss: 6.1967 - val_accuracy: 0.2708\n",
      "Epoch 31/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.8213\n",
      "Epoch 31: val_accuracy did not improve from 0.40972\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.4784 - accuracy: 0.8212 - val_loss: 6.7307 - val_accuracy: 0.1667\n",
      "Epoch 32/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.8247\n",
      "Epoch 32: val_accuracy improved from 0.40972 to 0.46528, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.4816 - accuracy: 0.8247 - val_loss: 3.0551 - val_accuracy: 0.4653\n",
      "Epoch 33/50\n",
      "70/72 [============================>.] - ETA: 0s - loss: 0.4398 - accuracy: 0.8536\n",
      "Epoch 33: val_accuracy did not improve from 0.46528\n",
      "72/72 [==============================] - 2s 26ms/step - loss: 0.4415 - accuracy: 0.8533 - val_loss: 9.4709 - val_accuracy: 0.1979\n",
      "Epoch 34/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4406 - accuracy: 0.8542\n",
      "Epoch 34: val_accuracy did not improve from 0.46528\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.4406 - accuracy: 0.8542 - val_loss: 15.5946 - val_accuracy: 0.1354\n",
      "Epoch 35/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4134 - accuracy: 0.8516\n",
      "Epoch 35: val_accuracy improved from 0.46528 to 0.47222, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.4134 - accuracy: 0.8516 - val_loss: 2.5446 - val_accuracy: 0.4722\n",
      "Epoch 36/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3656 - accuracy: 0.8618\n",
      "Epoch 36: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.3637 - accuracy: 0.8628 - val_loss: 10.0433 - val_accuracy: 0.1979\n",
      "Epoch 37/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.4129 - accuracy: 0.8394\n",
      "Epoch 37: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.4129 - accuracy: 0.8394 - val_loss: 5.8747 - val_accuracy: 0.1840\n",
      "Epoch 38/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3610 - accuracy: 0.8724\n",
      "Epoch 38: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.3604 - accuracy: 0.8724 - val_loss: 13.2954 - val_accuracy: 0.1562\n",
      "Epoch 39/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3550 - accuracy: 0.8741\n",
      "Epoch 39: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.3550 - accuracy: 0.8741 - val_loss: 5.4826 - val_accuracy: 0.3056\n",
      "Epoch 40/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.3115 - accuracy: 0.8873\n",
      "Epoch 40: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.3152 - accuracy: 0.8863 - val_loss: 6.8463 - val_accuracy: 0.2882\n",
      "Epoch 41/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2940 - accuracy: 0.8898\n",
      "Epoch 41: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.2940 - accuracy: 0.8898 - val_loss: 5.2028 - val_accuracy: 0.2569\n",
      "Epoch 42/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.8898\n",
      "Epoch 42: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.3006 - accuracy: 0.8898 - val_loss: 5.1832 - val_accuracy: 0.2812\n",
      "Epoch 43/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8873\n",
      "Epoch 43: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.2792 - accuracy: 0.8889 - val_loss: 5.0141 - val_accuracy: 0.3090\n",
      "Epoch 44/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9085\n",
      "Epoch 44: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.2760 - accuracy: 0.9062 - val_loss: 5.6399 - val_accuracy: 0.2708\n",
      "Epoch 45/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2543 - accuracy: 0.9054\n",
      "Epoch 45: val_accuracy did not improve from 0.47222\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.2543 - accuracy: 0.9054 - val_loss: 7.2589 - val_accuracy: 0.2639\n",
      "Epoch 46/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.8976\n",
      "Epoch 46: val_accuracy improved from 0.47222 to 0.48611, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.2909 - accuracy: 0.8976 - val_loss: 3.7261 - val_accuracy: 0.4861\n",
      "Epoch 47/50\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.9054\n",
      "Epoch 47: val_accuracy did not improve from 0.48611\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.2673 - accuracy: 0.9054 - val_loss: 5.0200 - val_accuracy: 0.2639\n",
      "Epoch 48/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9190\n",
      "Epoch 48: val_accuracy improved from 0.48611 to 0.58681, saving model to ser.h5\n",
      "72/72 [==============================] - 2s 29ms/step - loss: 0.2385 - accuracy: 0.9184 - val_loss: 2.1525 - val_accuracy: 0.5868\n",
      "Epoch 49/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.9023\n",
      "Epoch 49: val_accuracy did not improve from 0.58681\n",
      "72/72 [==============================] - 2s 27ms/step - loss: 0.2749 - accuracy: 0.8993 - val_loss: 7.6062 - val_accuracy: 0.2222\n",
      "Epoch 50/50\n",
      "71/72 [============================>.] - ETA: 0s - loss: 0.2162 - accuracy: 0.9217\n",
      "Epoch 50: val_accuracy did not improve from 0.58681\n",
      "72/72 [==============================] - 2s 28ms/step - loss: 0.2190 - accuracy: 0.9210 - val_loss: 3.2112 - val_accuracy: 0.4062\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xtrain, ytrain, batch_size = batch_size, epochs= epochs, validation_data = (xtest,ytest), callbacks=callbacks_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
